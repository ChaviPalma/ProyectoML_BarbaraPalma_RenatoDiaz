import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, OPTICS
from sklearn.mixture import GaussianMixture
from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt



def entrenamiento_clustering(final_anime_dataset: pd.DataFrame, parametros_clustering: dict) -> tuple:
    
    try:
        df_animes = final_anime_dataset.drop_duplicates(subset=['id_anime']).copy()
    except NameError:
        # df_animes = pd.read_parquet("final_animedataset (1).parquet").drop_duplicates(subset=['IDAnime'])
        print("âš ï¸ AsegÃºrate de haber cargado el dataset en la variable 'df' o 'anime'.")

    print(f"ğŸ“‰ Animes Ãºnicos iniciales: {len(df_animes)}")

    features_cols = parametros_clustering["features_cols"]

    # --- CORRECCIÃ“N IMPORTANTE: FORZAR NUMÃ‰RICO ---
    print("ğŸ§¹ Limpiando valores 'UNKNOWN' y textos extraÃ±os...")
    for col in features_cols:
        if col in df_animes.columns:
            df_animes[col] = pd.to_numeric(df_animes[col], errors='coerce')
        else:
            print(f"Advertencia: La columna '{col}' no se encontrÃ³ en df_animes. Se omitirÃ¡.")

    df_model = df_animes.dropna(subset=features_cols).copy()
    print(f"âœ… Datos limpios finales: {len(df_model)} animes listos para usar.")

    if len(df_model) > 0:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df_model[features_cols])
        print(f"ğŸš€ Escalado exitoso. Shape final: {X_scaled.shape}")
    else:
        print("âŒ Â¡Error! Te has quedado sin datos despuÃ©s de limpiar. Revisa tus columnas.")
    
    K_FINAL = parametros_clustering["K_FINAL"] 

    print(f"ğŸš€ Iniciando entrenamiento de 5 modelos con K={K_FINAL} (donde aplique)...")

    modelos_entrenados = []  # <-- lista donde guardaremos (nombre, modelo)

    # 1. K-MEANS (Algoritmo Principal - Particional)
    print("1ï¸âƒ£ Entrenando K-Means...")
    kmeans = KMeans(n_clusters=K_FINAL, random_state=42, n_init=10)
    df_model['cluster_kmeans'] = kmeans.fit_predict(X_scaled)
    modelos_entrenados.append(("kmeans", kmeans))

    # 2. CLUSTERING JERÃRQUICO (Aglomerativo)
    print("2ï¸âƒ£ Entrenando JerÃ¡rquico...")
    plt.figure(figsize=(10, 4))
    dendrogram(linkage(X_scaled[:1000], method='ward'))

    try:
        hierarchical = AgglomerativeClustering(n_clusters=K_FINAL)
        df_model['cluster_hierarchical'] = hierarchical.fit_predict(X_scaled)
        modelos_entrenados.append(("hierarchical", hierarchical))
    except MemoryError:
        print("âš ï¸ Memoria insuficiente para JerÃ¡rquico completo. Se omite.")

    # 3. DBSCAN (Basado en Densidad)
    print("3ï¸âƒ£ Entrenando DBSCAN...")
    dbscan = DBSCAN(eps=0.5, min_samples=5)
    df_model['cluster_dbscan'] = dbscan.fit_predict(X_scaled)
    modelos_entrenados.append(("dbscan", dbscan))

    # 4. GAUSSIAN MIXTURE MODELS (ProbabilÃ­stico)
    print("4ï¸âƒ£ Entrenando GMM...")
    gmm = GaussianMixture(n_components=K_FINAL, random_state=42)
    gmm.fit(X_scaled)
    df_model['cluster_gmm'] = gmm.predict(X_scaled)
    modelos_entrenados.append(("gmm", gmm))

    # 5. OPTICS (Densidad variable - Alternativa avanzada a DBSCAN)
    print("5ï¸âƒ£ Entrenando OPTICS...")
    optics = OPTICS(min_samples=5, xi=0.05, min_cluster_size=0.05)
    df_model['cluster_optics'] = optics.fit_predict(X_scaled)
    modelos_entrenados.append(("optics", optics))

    print("\nâœ… Â¡Los 5 modelos han sido entrenados y guardados en el DataFrame!")
    print("Columnas generadas:", [col for col in df_model.columns if 'cluster_' in col])

    # Retornar el DataFrame y la lista de modelos entrenados
    return df_model, modelos_entrenados, X_scaled